{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import torchvision\n",
    "from torchvision.transforms import *\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "\n",
    "import jpeg4py as jpeg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecord(object):\n",
    "    def __init__(self, row):\n",
    "        self._data = row\n",
    "\n",
    "    @property\n",
    "    def label(self):\n",
    "        return int(self._data[0])\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._data[1]\n",
    "\n",
    "    @property\n",
    "    def num_frames(self):\n",
    "        return int(self._data[2])\n",
    "\n",
    "\n",
    "class I3DDataSet(data.Dataset):\n",
    "    def __init__(self, root_path, list_file, sample_frames=32,\n",
    "                 image_tmpl='frame_{:06d}.jpg', transform=None,\n",
    "                 force_grayscale=False, train_mode=True, test_clips=10, chunk_set=None):\n",
    "        self.root_path = root_path\n",
    "        self.list_file = list_file\n",
    "        self.sample_frames = sample_frames\n",
    "        self.image_tmpl = image_tmpl\n",
    "        self.train_mode = train_mode\n",
    "        if not self.train_mode:\n",
    "            self.num_clips = test_clips\n",
    "\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = t.GroupToTensorStack()\n",
    "\n",
    "        self._parse_list(chunk_set)\n",
    "\n",
    "    def _load_image(self, video_dir, idx):\n",
    "        img_path = os.path.join(self.root_path, video_dir, self.image_tmpl.format(idx))\n",
    "        try:\n",
    "            # Loading images with PIL is much slower!!\n",
    "            return [Image.fromarray(jpeg.JPEG(img_path).decode())]\n",
    "        except IOError:\n",
    "            print(\"Couldn't load image:{}\".format(img_path))\n",
    "            return None\n",
    "\n",
    "    def _parse_list(self, chunk_set):\n",
    "        self.video_list = [VideoRecord(x.strip().split(' ')) for x in open(self.list_file)]\n",
    "        if chunk_set is not None:\n",
    "            self.video_list = self.video_list[chunk_set[0]:chunk_set[1]]\n",
    "\n",
    "    def _sample_indices(self, record):\n",
    "        \"\"\"\n",
    "        :param record: VideoRecord\n",
    "        :return: list\n",
    "        \"\"\"\n",
    "        expanded_sample_length = self.sample_frames * 4  # in order to drop every other frame\n",
    "        if record.num_frames >= expanded_sample_length:\n",
    "            start_pos = randint(record.num_frames - expanded_sample_length + 1)\n",
    "            offsets = range(start_pos, start_pos + expanded_sample_length, 4)\n",
    "        elif record.num_frames > self.sample_frames*2:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames*2 + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames*2, 2)\n",
    "        elif record.num_frames > self.sample_frames:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames, 1)\n",
    "        else:\n",
    "            offsets = np.sort(randint(record.num_frames, size=self.sample_frames))\n",
    "\n",
    "        offsets = [int(v) for v in offsets]\n",
    "        return offsets\n",
    "\n",
    "    def _get_test_indices(self, record):\n",
    "        tick = (record.num_frames - self.sample_frames*2 + 1) / float(self.num_clips)\n",
    "        sample_start_pos = np.array([int(tick * x) for x in range(self.num_clips)])\n",
    "        offsets = []\n",
    "        for p in sample_start_pos:\n",
    "            offsets.extend(range(p, p+self.sample_frames*2, 2))\n",
    "\n",
    "        checked_offsets = []\n",
    "        for f in offsets:\n",
    "            new_f = int(f)\n",
    "            if new_f < 0:\n",
    "                new_f = 0\n",
    "            elif new_f >= record.num_frames:\n",
    "                new_f = record.num_frames - 1\n",
    "            checked_offsets.append(new_f)\n",
    "\n",
    "        return checked_offsets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        t1 = time.time()\n",
    "        record = self.video_list[index]\n",
    "\n",
    "        if self.train_mode:\n",
    "            segment_indices = self._sample_indices(record)\n",
    "            process_data, label = self.get(record, segment_indices)\n",
    "            while process_data is None:\n",
    "                index = randint(0, len(self.video_list) - 1)\n",
    "                process_data, label = self.__getitem__(index)\n",
    "        else:\n",
    "            segment_indices = self._get_test_indices(record)\n",
    "            process_data, label = self.get(record, segment_indices)\n",
    "            if process_data is None:\n",
    "                raise ValueError('sample indices:', record.path, segment_indices)\n",
    "        print('Getting frames took: {:.3} s'.format(time.time() - t1))\n",
    "        return process_data, label\n",
    "\n",
    "    def get(self, record, indices):\n",
    "        uniq_imgs = {}\n",
    "        uniq_id = np.unique(indices)\n",
    "        for ind in uniq_id:\n",
    "            seg_img = self._load_image(record.path, ind)\n",
    "\n",
    "            if seg_img is None:\n",
    "                return None, None\n",
    "            uniq_imgs[ind] = seg_img\n",
    "\n",
    "        images = [uniq_imgs[i][0] for i in indices]\n",
    "        images = self.transform(images)\n",
    "        return images, record.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import jpeg4py as jpeg\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from numpy.random import randint\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class VideoRecord2(object):\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.video = cv2.VideoCapture(self.path)\n",
    "        self.num_frames = self.get_num_frames()\n",
    "        \n",
    "    def get_num_frames(self):\n",
    "        count = -1\n",
    "        ret = True\n",
    "        while(ret):\n",
    "            ret, frame = self.video.read()\n",
    "            count += 1\n",
    "        self.video.set(2, 0)\n",
    "        return count\n",
    "\n",
    "    def get_frames(self, indices):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "            indices : sorted list of frames indices\n",
    "        Returns:\n",
    "            images : Dictionary in format {frame_id: PIL Image}\n",
    "        \"\"\"\n",
    "        images = dict()\n",
    "        for count in range(min(indices), max(indices)+1):\n",
    "            ret, frame = self.video.read()\n",
    "            if ret is False:\n",
    "                print('Could not load frame {} from video {}'.format(count, self.path))\n",
    "                return None\n",
    "            \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            if count in indices:\n",
    "                images[count] = Image.fromarray(frame)\n",
    "        self.video.release()\n",
    "        return images\n",
    "\n",
    "\n",
    "class VideoDataset(data.Dataset):\n",
    "    def __init__(self, root_path, list_file, sample_frames=32,\n",
    "                 image_tmpl='frame_{:06d}.jpg', transform=None,\n",
    "                 train_mode=True, test_clips=10, num_channels=3):\n",
    "        self.root_path = root_path\n",
    "        self.list_file = list_file\n",
    "        self.sample_frames = sample_frames\n",
    "        self.num_channels = num_channels\n",
    "        self.image_tmpl = image_tmpl\n",
    "        self.transform = transform\n",
    "        self.train_mode = train_mode\n",
    "        if not self.train_mode:\n",
    "            self.num_clips = test_clips\n",
    "\n",
    "        self._parse_list()\n",
    "\n",
    "    def _load_image(self, video_dir, idx):\n",
    "        img_path = os.path.join(self.root_path, video_dir, self.image_tmpl.format(idx))\n",
    "        try:\n",
    "            # Loading images with PIL is slower.\n",
    "            return [Image.fromarray(jpeg.JPEG(img_path).decode()).convert('RGB')]\n",
    "        except IOError:\n",
    "            print(\"Couldn't load image:{}\".format(img_path))\n",
    "            return None\n",
    "\n",
    "    def _parse_list(self):\n",
    "        self.video_list = [x.strip().split(' ') for x in open(self.list_file)]\n",
    "\n",
    "    def _sample_indices(self, record):\n",
    "        \"\"\"\n",
    "        :param record: VideoRecord\n",
    "        :return: list\n",
    "        \"\"\"\n",
    "        expanded_sample_length = self.sample_frames * 4  # in order to drop every other frame\n",
    "        if record.num_frames >= expanded_sample_length:\n",
    "            start_pos = randint(record.num_frames - expanded_sample_length + 1)\n",
    "            offsets = range(start_pos, start_pos + expanded_sample_length, 4)\n",
    "        elif record.num_frames > self.sample_frames*2:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames*2 + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames*2, 2)\n",
    "        elif record.num_frames > self.sample_frames:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames, 1)\n",
    "        else:\n",
    "            offsets = np.sort(randint(record.num_frames, size=self.sample_frames))\n",
    "\n",
    "        offsets = [int(v) for v in offsets]\n",
    "        return offsets\n",
    "\n",
    "    def _get_test_indices(self, record):\n",
    "        tick = (record.num_frames - self.sample_frames*2 + 1) / float(self.num_clips)\n",
    "        sample_start_pos = np.array([int(tick * x) for x in range(self.num_clips)])\n",
    "        offsets = []\n",
    "        for p in sample_start_pos:\n",
    "            offsets.extend(range(p, p+self.sample_frames*2, 2))\n",
    "\n",
    "        checked_offsets = []\n",
    "        for f in offsets:\n",
    "            new_f = int(f)\n",
    "            if new_f < 0:\n",
    "                new_f = 0\n",
    "            elif new_f >= record.num_frames:\n",
    "                new_f = record.num_frames - 1\n",
    "            checked_offsets.append(new_f)\n",
    "\n",
    "        return checked_offsets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        t1 = time.time()\n",
    "        label, video_path = self.video_list[index]\n",
    "        record = VideoRecord2(os.path.join(self.root_path, video_path))\n",
    "\n",
    "        if self.train_mode:\n",
    "            segment_indices = self._sample_indices(record)\n",
    "            process_data = self.get(record, segment_indices)\n",
    "            while process_data is None:\n",
    "                index = randint(0, len(self.video_list) - 1)\n",
    "                process_data, label = self.__getitem__(index)\n",
    "        else:\n",
    "            segment_indices = self._get_test_indices(record)\n",
    "            process_data = self.get(record, segment_indices)\n",
    "            if process_data is None:\n",
    "                raise ValueError\n",
    "        print('Getting frames took: {:.3} s'.format(time.time() - t1))\n",
    "        \n",
    "        data = process_data.squeeze(0)\n",
    "        data = data.view(self.num_channels, -1, self.sample_frames, data.size(2), data.size(3)).contiguous()\n",
    "        data = data.permute(1, 0, 2, 3, 4).contiguous()\n",
    "        \n",
    "        return data, int(label)\n",
    "\n",
    "    def get(self, record, indices):\n",
    "        uniq_imgs = {}\n",
    "        uniq_id = np.unique(indices)\n",
    "        uniq_imgs = record.get_frames(uniq_id)\n",
    "        \n",
    "        if uniq_imgs is None:\n",
    "            return None\n",
    "\n",
    "        images = [uniq_imgs[i] for i in indices]\n",
    "        images = self.transform(images)\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupCenterCrop(object):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.worker = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "    \n",
    "    \n",
    "class GroupNormalize(object):\n",
    "    def __init__(self, mean=None, std=None, num_channels=3):\n",
    "        self.mean = mean if mean is not None else [0] * num_channels\n",
    "        self.std = std if std is not None else [1] * num_channels\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "            \n",
    "        return tensor\n",
    "    \n",
    "\n",
    "class GroupResize(object):\n",
    "\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        self.worker = torchvision.transforms.Resize(size, interpolation)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return [self.worker(img) for img in img_group]\n",
    "    \n",
    "    \n",
    "class GroupToTensorStack(object):\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return torch.stack([torchvision.transforms.ToTensor()(img) for img in img_group], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/media/v-pakova/New Volume1/Datasets/Kinetics/400/val_clips_256_list.txt'\n",
    "\n",
    "input_mean = [0.5, 0.1, 0.9]\n",
    "input_std = [0.225, 0.1, 0.5]\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        VideoDataset(\"/media/v-pakova/New Volume1/Datasets/Kinetics/400/val_clips_256\", \n",
    "                   test_list, \n",
    "                   image_tmpl=\"frame_{:06d}.jpg\",\n",
    "                   train_mode=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       GroupResize(256),\n",
    "                       GroupToTensorStack(),\n",
    "#                        GroupNormalize(mean=input_mean),\n",
    "                    ])),\n",
    "        batch_size=1, shuffle=False) #, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting frames took: 8.47 s\n",
      "(0, torch.Size([1, 10, 3, 32, 256, 340]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "video_data_gen = enumerate(data_loader)\n",
    "for i, (mydata, label) in video_data_gen:\n",
    "    print((i, mydata.shape, label))\n",
    "    video_data = mydata\n",
    "#     if i > 3:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/media/v-pakova/New Volume/Datasets/Kinetics/400/val_list.txt'\n",
    "\n",
    "input_mean = [0.5, 0.1, 0.9]\n",
    "input_std = [0.225, 0.1, 0.5]\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        I3DDataSet(\"/media/v-pakova/New Volume/Datasets/Kinetics/400/val_frames_256\", \n",
    "                   test_list, \n",
    "                   image_tmpl=\"frame_{:06d}.jpg\",\n",
    "                   train_mode=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       GroupResize(256),\n",
    "                       GroupToTensorStack(),\n",
    "#                        GroupNormalize(mean=input_mean),\n",
    "                    ])),\n",
    "        batch_size=1, shuffle=False) #, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting frames took: 2.43 s\n",
      "(0, torch.Size([1, 3, 320, 256, 340]), tensor([0]))\n",
      "Getting frames took: 2.25 s\n",
      "(1, torch.Size([1, 3, 320, 256, 454]), tensor([0]))\n",
      "Getting frames took: 2.66 s\n",
      "(2, torch.Size([1, 3, 320, 256, 340]), tensor([0]))\n",
      "Getting frames took: 3.32 s\n",
      "(3, torch.Size([1, 3, 320, 256, 454]), tensor([0]))\n",
      "Getting frames took: 2.04 s\n",
      "(4, torch.Size([1, 3, 320, 256, 340]), tensor([0]))\n",
      "Getting frames took: 1.99 s\n",
      "(5, torch.Size([1, 3, 320, 256, 454]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "frame_data_gen = enumerate(data_loader)\n",
    "for i, (mydata, label) in frame_data_gen:\n",
    "    print((i, mydata.shape, label))\n",
    "    frame_data = mydata\n",
    "    if i > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[[[[0, 1, 0,  ..., 1, 0, 0],\n",
      "           [0, 1, 0,  ..., 0, 0, 0],\n",
      "           [0, 1, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 1, 1],\n",
      "           [0, 0, 0,  ..., 0, 1, 1],\n",
      "           [0, 0, 0,  ..., 0, 1, 1]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 1,  ..., 1, 1, 1],\n",
      "           [0, 0, 0,  ..., 1, 1, 1],\n",
      "           [0, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "          [[0, 1, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 1],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 1, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 1],\n",
      "           [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 1, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "         [[[0, 1, 0,  ..., 0, 0, 0],\n",
      "           [0, 1, 0,  ..., 0, 0, 0],\n",
      "           [0, 1, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 1, 0, 0],\n",
      "           [0, 0, 0,  ..., 1, 0, 0],\n",
      "           [0, 0, 0,  ..., 1, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[1, 0, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 1, 0,  ..., 0, 1, 0],\n",
      "           [0, 0, 0,  ..., 0, 1, 0],\n",
      "           [0, 0, 0,  ..., 0, 1, 0]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 1, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 1, 1],\n",
      "           [0, 0, 0,  ..., 0, 1, 1],\n",
      "           [0, 0, 0,  ..., 0, 1, 1]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 1, 1, 1],\n",
      "           [0, 0, 1,  ..., 1, 1, 1],\n",
      "           [0, 0, 0,  ..., 1, 1, 1]],\n",
      "\n",
      "          [[0, 1, 1,  ..., 0, 0, 0],\n",
      "           [0, 0, 1,  ..., 0, 0, 0],\n",
      "           [0, 0, 1,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 1],\n",
      "           [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           [1, 1, 1,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 1, 1],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "          [[0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           ...,\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0],\n",
      "           [0, 0, 0,  ..., 0, 0, 0]]]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(frame_data, video_data))\n",
    "print(frame_data == video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-567e26c76256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddnon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, time_kernel=1, space_stride=1, downsample=None, addnon=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, \n",
    "                               planes, \n",
    "                               kernel_size=(time_kernel,1,1), \n",
    "                               padding=(int((time_kernel-1)/2), 0,0),\n",
    "                               bias=False) # timepadding: make sure time-dim not reduce\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes, \n",
    "                               planes, \n",
    "                               kernel_size=(1,3,3), \n",
    "                               stride=(1,space_stride,space_stride),\n",
    "                               padding=(0,1,1), \n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, \n",
    "                               planes * 4, \n",
    "                               kernel_size=(1,1,1), \n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.addnon = addnon\n",
    "        if self.addnon:\n",
    "            self.nonlocal_block = NonLocalBlock3D(in_channels=planes * 4, mode='embedded_gaussian')\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        if self.addnon:\n",
    "            out = self.nonlocal_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class I3DResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, frame_num=32, num_classes=400):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        self.inplanes = 64\n",
    "        super(I3DResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, \n",
    "                               kernel_size=(5,7,7), \n",
    "                               stride=(2,2,2), \n",
    "                               padding=(2,3,3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1))\n",
    "        self.layer1 = self._make_layer_inflat(block, 64, layers[0], first_block=True)\n",
    "        self.temporalpool = nn.MaxPool3d(kernel_size=(3,1,1), stride=(2,1,1), padding=(1,0,0))\n",
    "        self.layer2 = self._make_layer_inflat(block, 128, layers[1], space_stride=2)\n",
    "        self.layer3 = self._make_layer_inflat(block, 256, layers[2], space_stride=2)\n",
    "        self.layer4 = self._make_layer_inflat(block, 512, layers[3], space_stride=2)\n",
    "        self.avgpool = nn.AvgPool3d((int(frame_num/8),7,7))\n",
    "        self.avgdrop =nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "   \n",
    "    def _make_layer_inflat(self, block, planes, blocks, space_stride=1, first_block=False):\n",
    "        downsample = None\n",
    "        if space_stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=(1,1,1), stride=(1,space_stride,space_stride), bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        if blocks%2 == 0 or first_block:\n",
    "            time_kernel = 3\n",
    "        else:\n",
    "            time_kernel = 1\n",
    "            \n",
    "        # Add first block\n",
    "        layers.append(block(self.inplanes, planes, time_kernel, space_stride, downsample, addnon = False))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        if first_block:\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "        elif blocks%2 == 0:\n",
    "            time_kernel = 1\n",
    "            add_nonlocal = True\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel, addnon=add_nonlocal))\n",
    "                time_kernel = (time_kernel + 2)%4\n",
    "                add_nonlocal = not add_nonlocal\n",
    "        else:\n",
    "            time_kernel = 3\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "                time_kernel = (time_kernel + 2)%4\n",
    "         \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.temporalpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.avgdrop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = I3DResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=3, mode='embedded_gaussian',\n",
    "                 sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "        assert mode in ['embedded_gaussian', 'gaussian', 'dot_product', 'concatenation']\n",
    "\n",
    "        # print('Dimension: %d, mode: %s' % (dimension, mode))\n",
    "\n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool = nn.MaxPool3d\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool = nn.MaxPool2d\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool = nn.MaxPool1d\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)       \n",
    "        nn.init.kaiming_normal_(self.g.weight)\n",
    "        nn.init.constant_(self.g.bias,0)\n",
    "        \n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            nn.init.kaiming_normal_(self.W[0].weight)\n",
    "            nn.init.constant_(self.W[0].bias, 0)\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.kaiming_normal(self.W.weight)\n",
    "            nn.init.constant(self.W.bias, 0)\n",
    "\n",
    "        self.theta = None\n",
    "        self.phi = None\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.mode == \"embedded_gaussian\":\n",
    "            self.operation_function = self._embedded_gaussian\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool(kernel_size=2))\n",
    "            if self.phi is None:\n",
    "                self.phi = max_pool(kernel_size=2)\n",
    "            else:\n",
    "                self.phi = nn.Sequential(self.phi, max_pool(kernel_size=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        output = self.operation_function(x)\n",
    "        return output\n",
    "\n",
    "    def _embedded_gaussian(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # g=>(b, c, t, h, w)->(b, 0.5c, t, h, w)->(b, thw, 0.5c)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        # theta=>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, thw, 0.5c)\n",
    "        # phi  =>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, 0.5c, thw)\n",
    "        # f=>(b, thw, 0.5c)dot(b, 0.5c, twh) = (b, thw, thw)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        # (b, thw, thw)dot(b, thw, 0.5c) = (b, thw, 0.5c)->(b, 0.5c, t, h, w)->(b, c, t, h, w)\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "class NonLocalBlock3D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded_gaussian', sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock3D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=3, mode=mode,\n",
    "                                              sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weigths_i3dResNet(weigths_file_path, new_model, save_model=False, new_model_name=None):\n",
    "    with open(weigths_file_path, 'rb') as model_file:\n",
    "        pretrained_data = pickle.load(model_file, encoding='latin1')\n",
    "\n",
    "    pretrained_data1 = pretrained_data['blobs']\n",
    "    # Removing training parameters\n",
    "    pretrained_data2 = {k: v for k, v in pretrained_data1.items() if\n",
    "                        ('momentum' not in k) and ('bn_rm' not in k) and ('bn_riv' not in k)\n",
    "                        and ('lr' not in k) and ('model_iter' not in k)}\n",
    "\n",
    "    pretrained_data_list = sorted(pretrained_data2.items())\n",
    "\n",
    "    # Renaming layers\n",
    "    pretrained_data3 = {}\n",
    "    for k, v in pretrained_data_list:\n",
    "        a = k[:]\n",
    "        # Correcting the end\n",
    "        if a[-2:] == '_b':\n",
    "            a = a[:-2]+'.bias'\n",
    "        elif a[-2:] == '_s' or a[-2:] == '_w':\n",
    "            a = a[:-2]+'.weight'\n",
    "\n",
    "        # Correcting the begin\n",
    "        a = a.replace('res_conv1_bn', 'bn1')\n",
    "        a = a.replace('pred', 'fc')\n",
    "        r = re.compile('res._*')\n",
    "        if r.match(a) is not None:\n",
    "            layer = int(a[3])-1\n",
    "            a = 'layer'+str(layer)+'.'+a[5:]\n",
    "\n",
    "        # Correcting the middle\n",
    "        a = a.replace('_branch1_bn', '.downsample.1')\n",
    "        a = a.replace('_branch1', '.downsample.0')\n",
    "\n",
    "        for i, l in enumerate(['a', 'b', 'c']):\n",
    "            a = a.replace('_branch2{}_bn'.format(l), '.bn{}'.format(i+1))\n",
    "            a = a.replace('_branch2{}'.format(l), '.conv{}'.format(i+1))\n",
    "\n",
    "        # Correcting nonlocal\n",
    "        if 'nonlocal' in a:\n",
    "            layer = int(a[13])-1\n",
    "            sub_layer = a[15]\n",
    "            a = 'layer{}.{}.nonlocal_block.'.format(layer, sub_layer) + a[17:]\n",
    "            a = a.replace('out', 'W.0')\n",
    "            a = a.replace('bn', 'W.1')\n",
    "            a = a.replace('phi', 'phi.0')\n",
    "            a = a.replace('.g.', '.g.0.')\n",
    "\n",
    "        pretrained_data3[a] = {'old_name': k, 'data': v}\n",
    "\n",
    "    # Checking name, shape and number of layers\n",
    "    param_i3d_keys = new_model.state_dict().keys()\n",
    "    count = 0\n",
    "    for k, v in pretrained_data3.items():\n",
    "        assert(k in param_i3d_keys)\n",
    "        count += 1\n",
    "        assert(new_model.state_dict()[k].shape == v['data'].shape)\n",
    "\n",
    "    assert count == len(list(new_model.named_parameters()))\n",
    "\n",
    "    # Copying weigths\n",
    "    for k, v in new_model.named_parameters():\n",
    "        new_data = pretrained_data3[k]['data']\n",
    "        v.data = nn.Parameter(torch.Tensor(new_data))\n",
    "\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d036f74c0c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblank_i3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../resnet50_i3d_pre_trained.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# pre_trained_file = (\"/media/v-pakova/New Volume/OnlineActionRecognition/models/pre-trained/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                         \"non-local/i3d_nonlocal_32x2_IN_pretrain_400k.pkl\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# resnet_i3d = copy_weigths_i3dResNet(pre_trained_file, blank_i3d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet50' is not defined"
     ]
    }
   ],
   "source": [
    "blank_i3d = resnet50()\n",
    "loaded_model = torch.load('../resnet50_i3d_pre_trained.pt')\n",
    "# pre_trained_file = (\"/media/v-pakova/New Volume/OnlineActionRecognition/models/pre-trained/\"\n",
    "#                         \"non-local/i3d_nonlocal_32x2_IN_pretrain_400k.pkl\")\n",
    "# resnet_i3d = copy_weigths_i3dResNet(pre_trained_file, blank_i3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "0\n",
      "67\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4c60e3f7513e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#     r1 = blank_i3d(input_var).data.cpu().numpy().copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#     r2 = loaded_model(input_var).data.cpu().numpy().copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mr3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_i3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#     r11 = r1.reshape((10*1, 400)).mean(axis=0).reshape((1, 400))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (mydata, label) in data_gen:\n",
    "#     print((i, mydata.shape, label))\n",
    "    d1 = mydata.squeeze(0)\n",
    "    d2 = d1.view(3, -1, 32, d1.size(2), d1.size(3)).contiguous()\n",
    "    d3 = d2.permute(1,0,2,3,4).contiguous()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_var = torch.Tensor(d3.cuda())\n",
    "\n",
    "    #     r1 = blank_i3d(input_var).data.cpu().numpy().copy()\n",
    "    #     r2 = loaded_model(input_var).data.cpu().numpy().copy()\n",
    "        r3 = resnet_i3d(input_var).data.cpu().numpy().copy()\n",
    "\n",
    "    #     r11 = r1.reshape((10*1, 400)).mean(axis=0).reshape((1, 400))\n",
    "    #     r22 = r2.reshape((10*1, 400)).mean(axis=0).reshape((1, 400))\n",
    "        r33 = r3.reshape((10*1, 400)).mean(axis=0).reshape((1, 400))\n",
    "\n",
    "        print(np.argmax(r33))#, np.argmax(r22), np.argmax(r33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare blank with loaded\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "Compare blank with copied\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resnet_i3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be4e400e50db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Compare blank with copied'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblank_i3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_i3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet_i3d' is not defined"
     ]
    }
   ],
   "source": [
    "print('Compare blank with loaded')\n",
    "for p1, p2 in zip(blank_i3d.parameters(), loaded_model.parameters()):\n",
    "    if p1.data.ne(p2.data).sum() > 0:\n",
    "        print(False)\n",
    "print(True)\n",
    "\n",
    "print('Compare blank with copied')\n",
    "for p1, p2 in zip(blank_i3d.parameters(), resnet_i3d.parameters()):\n",
    "    if p1.data.ne(p2.data).sum() > 0:\n",
    "        print(False)\n",
    "print(True)\n",
    "\n",
    "print('Compare loaded with copied')\n",
    "for p1, p2 in zip(resnet_i3d.parameters(), loaded_model.parameters()):\n",
    "    if p1.data.ne(p2.data).sum() > 0:\n",
    "        print(False)\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
