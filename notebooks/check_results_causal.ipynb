{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of video |  Top1   |  Top5  \n",
      "    10     |  61.49  |  81.87 \n",
      "    20     |  64.21  |  83.16 \n",
      "    30     |  65.68  |  84.90 \n",
      "    40     |  67.46  |  85.98 \n",
      "    50     |  68.92  |  86.63 \n",
      "    60     |  70.40  |  87.86 \n",
      "    70     |  71.30  |  88.46 \n",
      "    80     |  71.94  |  88.71 \n",
      "    90     |  72.03  |  89.41 \n",
      "   100     |  72.57  |  89.72 \n"
     ]
    }
   ],
   "source": [
    "file_path = '/media/v-pakova/New Volume1/OnlineActionRecognition/outputs/val_short_id3_baseline_causal.csv'\n",
    "labels = []\n",
    "all_preds = [[] for i in range(10)]\n",
    "with open(file_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    headers = next(reader, None)\n",
    "    for row in reader:\n",
    "        labels.append(int(row[0]))\n",
    "        for i in range(10):\n",
    "            all_preds[i].append(np.fromstring(row[i+1], dtype=int, sep=' '))\n",
    "\n",
    "print('{:^10} | {:^7} | {:^7}'.format('% of video', 'Top1', 'Top5'))\n",
    "for i in range(10):\n",
    "    preds = all_preds[i]\n",
    "    \n",
    "    top1_pred = [p[0] for p in preds]\n",
    "    top5_pred = []\n",
    "    for l, p in zip(labels, preds):\n",
    "        if l in p:\n",
    "            top5_pred.append(l)\n",
    "        else:\n",
    "            top5_pred.append(p[0])\n",
    "    \n",
    "    # TOP1 RESULTS\n",
    "    cf = confusion_matrix(labels, top1_pred).astype(float)\n",
    "    cls_cnt = cf.sum(axis=1)\n",
    "    cls_hit = np.diag(cf)\n",
    "\n",
    "    cls_acc = [h/c if c > 0 else None for (h, c) in zip(cls_hit, cls_cnt)]\n",
    "    cls_acc1 = [x for x in cls_acc if x is not None]\n",
    "    \n",
    "    # TOP5 RESULTS\n",
    "    cf = confusion_matrix(labels, top5_pred).astype(float)\n",
    "    cls_cnt = cf.sum(axis=1)\n",
    "    cls_hit = np.diag(cf)\n",
    "\n",
    "    cls_acc = [h/c if c > 0 else None for (h, c) in zip(cls_hit, cls_cnt)]\n",
    "    cls_acc5 = [x for x in cls_acc if x is not None]\n",
    "    \n",
    "    print('{:^10} | {:^7.02f} | {:^7.02f}'.format((i+1)*10, np.mean(cls_acc1) * 100, np.mean(cls_acc5) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
