{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['I3DResNet', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, time_kernel=1, space_stride=1, downsample=None, addnon=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, \n",
    "                               planes, \n",
    "                               kernel_size=(time_kernel,1,1), \n",
    "                               padding=(int((time_kernel-1)/2), 0,0),\n",
    "                               bias=False) # timepadding: make sure time-dim not reduce\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes, \n",
    "                               planes, \n",
    "                               kernel_size=(1,3,3), \n",
    "                               stride=(1,space_stride,space_stride),\n",
    "                               padding=(0,1,1), \n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes, \n",
    "                               planes * 4, \n",
    "                               kernel_size=(1,1,1), \n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.addnon = addnon\n",
    "        if self.addnon:\n",
    "            self.nonlocal_block = NonLocalBlock3D(in_channels=planes * 4, mode='embedded_gaussian')\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        if self.addnon:\n",
    "            out = self.nonlocal_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class I3DResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, frame_num=32, num_classes=400):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        self.inplanes = 64\n",
    "        super(I3DResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, \n",
    "                               kernel_size=(5,7,7), \n",
    "                               stride=(2,2,2), \n",
    "                               padding=(2,3,3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1))\n",
    "        self.layer1 = self._make_layer_inflat(block, 64, layers[0], first_block=True)\n",
    "        self.temporalpool = nn.MaxPool3d(kernel_size=(3,1,1), stride=(2,1,1), padding=(1,0,0))\n",
    "        self.layer2 = self._make_layer_inflat(block, 128, layers[1], space_stride=2)\n",
    "        self.layer3 = self._make_layer_inflat(block, 256, layers[2], space_stride=2)\n",
    "        self.layer4 = self._make_layer_inflat(block, 512, layers[3], space_stride=2)\n",
    "        self.avgpool = nn.AvgPool3d((int(frame_num/8),7,7))\n",
    "        self.avgdrop =nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "   \n",
    "    def _make_layer_inflat(self, block, planes, blocks, space_stride=1, first_block=False):\n",
    "        downsample = None\n",
    "        if space_stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=(1,1,1), stride=(1,space_stride,space_stride), bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        if blocks%2 == 0 or first_block:\n",
    "            time_kernel = 3\n",
    "        else:\n",
    "            time_kernel = 1\n",
    "            \n",
    "        # Add first block\n",
    "        layers.append(block(self.inplanes, planes, time_kernel, space_stride, downsample, addnon = False))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        \n",
    "        if first_block:\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "        elif blocks%2 == 0:\n",
    "            time_kernel = 1\n",
    "            add_nonlocal = True\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel, addnon=add_nonlocal))\n",
    "                time_kernel = (time_kernel + 2)%4\n",
    "                add_nonlocal = not add_nonlocal\n",
    "        else:\n",
    "            time_kernel = 3\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "                time_kernel = (time_kernel + 2)%4\n",
    "         \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.temporalpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.avgdrop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = I3DResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, dimension=3, mode='embedded_gaussian',\n",
    "                 sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "        assert mode in ['embedded_gaussian', 'gaussian', 'dot_product', 'concatenation']\n",
    "\n",
    "        # print('Dimension: %d, mode: %s' % (dimension, mode))\n",
    "\n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool = nn.MaxPool3d\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool = nn.MaxPool2d\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool = nn.MaxPool1d\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)       \n",
    "        nn.init.kaiming_normal_(self.g.weight)\n",
    "        nn.init.constant_(self.g.bias,0)\n",
    "        \n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                        kernel_size=1, stride=1, padding=0),\n",
    "                bn(self.in_channels)\n",
    "            )\n",
    "            nn.init.kaiming_normal_(self.W[0].weight)\n",
    "            nn.init.constant_(self.W[0].bias, 0)\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.kaiming_normal(self.W.weight)\n",
    "            nn.init.constant(self.W.bias, 0)\n",
    "\n",
    "        self.theta = None\n",
    "        self.phi = None\n",
    "\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        if self.mode == \"embedded_gaussian\":\n",
    "            self.operation_function = self._embedded_gaussian\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool(kernel_size=2))\n",
    "            if self.phi is None:\n",
    "                self.phi = max_pool(kernel_size=2)\n",
    "            else:\n",
    "                self.phi = nn.Sequential(self.phi, max_pool(kernel_size=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        output = self.operation_function(x)\n",
    "        return output\n",
    "\n",
    "    def _embedded_gaussian(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # g=>(b, c, t, h, w)->(b, 0.5c, t, h, w)->(b, thw, 0.5c)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        # theta=>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, thw, 0.5c)\n",
    "        # phi  =>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, 0.5c, thw)\n",
    "        # f=>(b, thw, 0.5c)dot(b, 0.5c, twh) = (b, thw, thw)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        # (b, thw, thw)dot(b, thw, 0.5c) = (b, thw, 0.5c)->(b, 0.5c, t, h, w)->(b, c, t, h, w)\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "class NonLocalBlock3D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded_gaussian', sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock3D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              dimension=3, mode=mode,\n",
    "                                              sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load('resnet50_i3d_pre_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kinetics400Dataset(data.Dataset):\n",
    "    def __init__(self, root_dir, list_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.landmarks_frame = self.read_list_file(list_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.landmarks_frame[idx][1])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        image = np.rollaxis(np.asarray(image), 2, 0)\n",
    "        label = int(self.landmarks_frame[idx][0])\n",
    "#         print(image.shape, label)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def read_list_file(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            frame_list = file.readlines()\n",
    "        for i, line in enumerate(frame_list):\n",
    "            frame_list[i] = line.replace('\\n', '').split(' ')\n",
    "        return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/v-pakova/New Volume/OnlineActionRecognition/datasets/Kinetics-NonLocal/val'\n",
    "list_file = '/media/v-pakova/New Volume/OnlineActionRecognition/datasets/Kinetics-NonLocal/val_list.txt'\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "    ])\n",
    "\n",
    "dataset = Kinetics400Dataset(root_dir, list_file, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n",
      "0 torch.Size([5, 3, 224, 224]) tensor([0, 0, 0, 0, 0])\n",
      "(3, 224, 224) 0\n",
      "(3, 224, 224) 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 5-dimensional input for 5-dimensional weight [64, 3, 5, 7, 7], but got 4-dimensional input of size [5, 3, 224, 224] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-faf926a43ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-55d636c63627>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 448\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 5-dimensional input for 5-dimensional weight [64, 3, 5, 7, 7], but got 4-dimensional input of size [5, 3, 224, 224] instead"
     ]
    }
   ],
   "source": [
    "total_loss = []\n",
    "total_acc = 0\n",
    "total_sample = 0\n",
    "\n",
    "for test_batch_index, (img_batch, label_batch) in enumerate(dataloader):\n",
    "    print(test_batch_index, img_batch.shape, label_batch)\n",
    "    if torch.cuda.is_available():\n",
    "        img_batch = img_batch.cuda()\n",
    "        \n",
    "    \n",
    "    \n",
    "    predict = loaded_model(img_batch)\n",
    "    loss = loss_func(predict, label_batch)\n",
    "\n",
    "    predict = predict.argmax(dim=1)\n",
    "    acc = (predict == label_batch).sum()\n",
    "    print(predict, acc)\n",
    "    total_loss.append(loss)\n",
    "    total_acc += acc\n",
    "    total_sample += img_batch.size(0)\n",
    "    print(total_sample)\n",
    "    \n",
    "    if total_sample > 10:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
