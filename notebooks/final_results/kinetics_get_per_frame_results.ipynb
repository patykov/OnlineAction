{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.nn import MaxPool1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_0.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_1.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_2.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_3.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_4.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_5.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_6.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop/causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop_7.txt\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"causal_eval_kinetics_r50_i3d_baseline8_stream_centerCrop\"\n",
    "files_dir = \"/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/\" + dir_name\n",
    "\n",
    "result_files = sorted([os.path.join(files_dir, f) for f in os.listdir(files_dir) if f.endswith('.txt')])\n",
    "\n",
    "split_text = []\n",
    "for fid, fname in enumerate(result_files):\n",
    "    print(fname)\n",
    "    with open(fname, 'r', encoding =\"ISO-8859-1\") as infile:\n",
    "#         a = infile.readline()\n",
    "#         print(a)\n",
    "        for line in infile:\n",
    "            split_text.append(line.strip().split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['driving_tractor/cn2OQeIdLcw.mp4_000089 ',\n",
       " ' 104 ',\n",
       " ' 104 103 201 372 199 ',\n",
       " ' 0.912668   0.01153553 0.0073093  0.00532365 0.00346765']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text2 = []\n",
    "for i, line in enumerate(split_text):\n",
    "    if len(line) == 1:\n",
    "        aux = split_text2[-1][-1].replace(line[0], '') + ' ' + line[0]\n",
    "        preds = np.fromstring(aux, dtype=float, sep=' ')\n",
    "        split_text2[-1][-1] = aux\n",
    "        \n",
    "    elif len(line) == 4:\n",
    "        split_text2.append(line)\n",
    "    else:\n",
    "        print(line)\n",
    "        \n",
    "%xdel split_text\n",
    "split_text = split_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_predictions(ids, preds, num_classes=400):\n",
    "    full_preds = np.zeros((num_classes))\n",
    "    full_preds[ids] = preds\n",
    "    return full_preds\n",
    "\n",
    "\n",
    "def divide_per_clip(split_text):\n",
    "    clips_targets = []\n",
    "    clips_prediction = []\n",
    "\n",
    "    video_name = None\n",
    "    for i, [video_path, target, label, pred] in enumerate(split_text):\n",
    "        video = re.sub('()_\\\\d{6}', '', video_path.strip())\n",
    "        if video != video_name or i == len(split_text):            \n",
    "            # new video! But first, save old video\n",
    "            if i > 0:\n",
    "                video_targets = np.array(video_targets)\n",
    "                video_prediction = np.array(video_prediction)\n",
    "                \n",
    "                num_frames = video_prediction.shape[0]\n",
    "                if num_frames < 10:\n",
    "                    repeat_ids = np.round(np.linspace(0, num_frames - 1, 10)).astype(int)\n",
    "                    video_targets = video_targets[repeat_ids]\n",
    "                    video_prediction = video_prediction[repeat_ids]\n",
    "                    \n",
    "                clips_targets.append(video_targets)\n",
    "                clips_prediction.append(video_prediction)\n",
    "                    \n",
    "            # star new one\n",
    "            video_targets = []\n",
    "            video_prediction = []\n",
    "            video_name = video\n",
    "            \n",
    "        video_targets.append(int(target))\n",
    "        labels = np.fromstring(label, dtype=int, sep=' ')\n",
    "        preds = np.fromstring(pred, dtype=float, sep=' ')\n",
    "        video_prediction.append(get_full_predictions(labels, preds))\n",
    "                \n",
    "    return clips_targets, clips_prediction\n",
    "\n",
    "def select_n_clips(video_classes, n=10):\n",
    "    num_frames = len(video_classes)\n",
    "    ids = np.linspace(0, num_frames-1, n, dtype=int)\n",
    "    \n",
    "    return video_classes[ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing per clip\n",
    "clip_targets, clip_pred = divide_per_clip(split_text)\n",
    "\n",
    "\n",
    "# Getting result of 10 clips\n",
    "clip_pred_10 = [select_n_clips(np.array(clip_data), n=10) for clip_data in clip_pred]\n",
    "\n",
    "clip_pred_10_mean = np.array([t_c.mean(axis=0) for t_c in clip_pred_10])\n",
    "clip_gt_10 = np.array([clip_data[0] for clip_data in clip_targets])\n",
    "\n",
    "\n",
    "# Dividing all frames in percentages\n",
    "p_clip_targets = np.array([np.array_split(ct, 10) for ct in clip_targets])\n",
    "p_clip_pred = np.array([np.array_split(cp, 10) for cp in clip_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_videos = p_clip_targets.shape[0]\n",
    "num_percent = p_clip_targets.shape[1]\n",
    "num_topk = 5\n",
    "\n",
    "percentage_targets = np.zeros((num_videos, num_percent))\n",
    "percentage_pred = np.zeros((num_videos, num_percent, num_topk))\n",
    "\n",
    "for clip_id, (p_targets, p_preds) in enumerate(zip(p_clip_targets, p_clip_pred)):\n",
    "    for p_id in range(10):\n",
    "        pt = np.hstack(p_targets[:p_id+1])\n",
    "        pp = np.vstack(p_preds[:p_id+1])\n",
    "        assert len(set(pt)) == 1  # Checking if all targets match\n",
    "        percentage_targets[clip_id, p_id] = pt[0]\n",
    "        preds = torch.tensor(pp)\n",
    "        mean_pp = preds.mean(0)\n",
    "        _, topk_labels = torch.topk(mean_pp, 5)\n",
    "        percentage_pred[clip_id, p_id] = topk_labels.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_predictions(video_pred, video_labels):\n",
    "    # TOP1\n",
    "    top1_pred = [p[0] for p in video_pred]\n",
    "    # TOP 5\n",
    "    top5_pred = []\n",
    "    for l, p in zip(video_labels, video_pred):\n",
    "        if l in p:\n",
    "            top5_pred.append(l)\n",
    "        else:\n",
    "            top5_pred.append(p[0])\n",
    "    return top1_pred, top5_pred\n",
    "\n",
    "\n",
    "def per_class_accuracy(predictions, labels):\n",
    "    cf = confusion_matrix(labels, predictions).astype(float)\n",
    "\n",
    "    cls_cnt = cf.sum(axis=1)\n",
    "    cls_hit = np.diag(cf)\n",
    "    return np.nanmean(cls_hit / cls_cnt)\n",
    "\n",
    "\n",
    "def get_per_frame_percent_results(p_targets, p_preds):\n",
    "    per_frame_percentage_results = []\n",
    "    for p_id in range(10):\n",
    "        p_t = p_targets[:, p_id]\n",
    "        p_p = p_preds[:, p_id]\n",
    "        top1_pred, top5_pred = get_top_predictions(p_p, p_t)\n",
    "\n",
    "        cls_acc1 = per_class_accuracy(top1_pred, p_t)\n",
    "        cls_acc5 = per_class_accuracy(top5_pred, p_t)\n",
    "        per_frame_percentage_results.append([cls_acc1, cls_acc5])\n",
    "        print((p_id+1)*10, cls_acc1, cls_acc5)\n",
    "    return np.array(per_frame_percentage_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7020829988562016, 0.891171358595158)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 clips results\n",
    "\n",
    "clip_top5_10 = []\n",
    "for mean_10 in clip_pred_10_mean:\n",
    "    _, topk_labels = torch.topk(torch.tensor(mean_10), 5)\n",
    "    clip_top5_10.append(topk_labels.numpy())\n",
    "    \n",
    "clip_top5_10 = np.array(clip_top5_10)\n",
    "\n",
    "top1_pred, top5_pred = get_top_predictions(clip_top5_10, clip_gt_10)\n",
    "\n",
    "cls_acc1_10 = per_class_accuracy(top1_pred, clip_gt_10)\n",
    "cls_acc5_10 = per_class_accuracy(top5_pred, clip_gt_10)\n",
    "\n",
    "cls_acc1_10, cls_acc5_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.6055639672957738 0.8109984888973532\n",
      "20 0.6222338067242006 0.8274481119413538\n",
      "30 0.6431794008483752 0.8454186539815096\n",
      "40 0.6620508723076872 0.8594927682661659\n",
      "50 0.6756582378453581 0.8700037823145825\n",
      "60 0.6833338483141554 0.8782477068401436\n",
      "70 0.6910413349522523 0.8831455881230497\n",
      "80 0.6961368434856072 0.8868778864599269\n",
      "90 0.6993808926290359 0.8889059503982683\n",
      "100 0.7010095130310975 0.8909292905966945\n"
     ]
    }
   ],
   "source": [
    "# All frames mean percentage results\n",
    "\n",
    "per_frame_percent_res = get_per_frame_percent_results(percentage_targets, percentage_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.concatenate((np.array([[cls_acc1_10, cls_acc5_10]]), per_frame_percent_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = files_dir + '_results'\n",
    "np.save(output_file, results, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline8_centerCrop = np.load(output_file+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71854441, 0.89811049],\n",
       "       [0.63530718, 0.84214335],\n",
       "       [0.64962369, 0.85534666],\n",
       "       [0.6685064 , 0.86938396],\n",
       "       [0.68446872, 0.87948983],\n",
       "       [0.6950135 , 0.88698023],\n",
       "       [0.70064095, 0.89364684],\n",
       "       [0.70767234, 0.89679222],\n",
       "       [0.71330734, 0.89830761],\n",
       "       [0.71603437, 0.89988545],\n",
       "       [0.71950334, 0.90005517]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_baseline32_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73355357, 0.91071791],\n",
       "       [0.65183775, 0.85287248],\n",
       "       [0.66693359, 0.8672611 ],\n",
       "       [0.6822416 , 0.87995986],\n",
       "       [0.69564461, 0.89168807],\n",
       "       [0.7076758 , 0.89937124],\n",
       "       [0.71635096, 0.90316556],\n",
       "       [0.72185032, 0.90700233],\n",
       "       [0.72674467, 0.9100338 ],\n",
       "       [0.73233295, 0.91069292],\n",
       "       [0.73417942, 0.91145335]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nl32_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.702083  , 0.89117136],\n",
       "       [0.60556397, 0.81099849],\n",
       "       [0.62223381, 0.82744811],\n",
       "       [0.6431794 , 0.84541865],\n",
       "       [0.66205087, 0.85949277],\n",
       "       [0.67565824, 0.87000378],\n",
       "       [0.68333385, 0.87824771],\n",
       "       [0.69104133, 0.88314559],\n",
       "       [0.69613684, 0.88687789],\n",
       "       [0.69938089, 0.88890595],\n",
       "       [0.70100951, 0.89092929]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_baseline8_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73935215, 0.91784009],\n",
       "       [0.65289267, 0.85684554],\n",
       "       [0.66969472, 0.86911939],\n",
       "       [0.68593682, 0.88189664],\n",
       "       [0.70082018, 0.89361338],\n",
       "       [0.711213  , 0.90102226],\n",
       "       [0.71994408, 0.90694043],\n",
       "       [0.7256107 , 0.90999549],\n",
       "       [0.73025136, 0.91263238],\n",
       "       [0.73550584, 0.91540209],\n",
       "       [0.73831541, 0.91741199]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nl8_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
