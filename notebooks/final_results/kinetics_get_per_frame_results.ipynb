{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch.nn import MaxPool1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_0.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_1.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_10.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_11.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_12.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_13.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_14.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_15.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_2.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_3.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_4.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_5.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_6.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_7.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_8.txt\n",
      "/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv/causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv_9.txt\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"causal_eval_kinetics_r50_i3d_nonlocal_8x8_fullyConv\"\n",
    "files_dir = \"/Volumes/UBUNTU 18_0/PAKOVA/outputs/Kinetics/\" + dir_name\n",
    "\n",
    "result_files = sorted([os.path.join(files_dir, f) for f in os.listdir(files_dir) if f.endswith('.txt')])\n",
    "\n",
    "# split_text = []\n",
    "text = ''\n",
    "for fid, fname in enumerate(result_files):\n",
    "    print(fname)\n",
    "    with open(fname, 'r', encoding =\"ISO-8859-1\") as infile:\n",
    "        for line in infile:\n",
    "            if line[0].isalpha():\n",
    "                line = '| ' + line\n",
    "            text += line.strip() + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to connect broken lines of new code (400 preds)\n",
    "split_text = text.split('|')\n",
    "\n",
    "if split_text[0] == '':\n",
    "    split_text = split_text[1:]\n",
    "    \n",
    "split_text2 = []\n",
    "for i in range(0, len(split_text), 3):\n",
    "    res = split_text[i:i+3]\n",
    "    split_text2.append(res)\n",
    "        \n",
    "        \n",
    "%xdel split_text\n",
    "split_text = split_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_predictions(ids, preds, num_classes=400):\n",
    "    miss = (1 - preds.sum()) / (num_classes - preds.shape[0])\n",
    "    full_preds = np.full((num_classes), miss)\n",
    "    full_preds[ids] = preds\n",
    "    return full_preds\n",
    "\n",
    "\n",
    "def divide_per_clip(split_text):\n",
    "    clips_targets = []\n",
    "    clips_labels = []\n",
    "    clips_prediction = []\n",
    "    clips_frames = []\n",
    "\n",
    "    video_name = None\n",
    "    for i, [video_path, target, pred] in enumerate(split_text):\n",
    "        video = re.sub('()_\\\\d{6}', '', video_path.strip())\n",
    "\n",
    "        if video != video_name:            \n",
    "            # new video! But first, save old video\n",
    "            if i > 0:\n",
    "                video_targets = np.array(video_targets)\n",
    "                video_labels = np.array(video_labels)\n",
    "                video_prediction = np.array(video_prediction)\n",
    "                \n",
    "                num_frames = video_prediction.shape[0]\n",
    "                if num_frames < 10:\n",
    "                    repeat_ids = np.round(np.linspace(0, num_frames - 1, 10)).astype(int)\n",
    "                    video_targets = video_targets[repeat_ids]\n",
    "                    video_labels = video_labels[repeat_ids]\n",
    "                    video_prediction = video_prediction[repeat_ids]\n",
    "                \n",
    "                clips_targets.append(video_targets)\n",
    "                clips_labels.append(video_labels)\n",
    "                clips_prediction.append(video_prediction)\n",
    "                clips_frames.append(video_frames)\n",
    "                    \n",
    "            # start new one\n",
    "            video_targets = []\n",
    "            video_labels = []\n",
    "            video_prediction = []\n",
    "            video_frames = []\n",
    "            video_name = video\n",
    "            \n",
    "        video_targets.append(int(target))\n",
    "\n",
    "        preds = np.fromstring(pred, dtype=float, sep=' ')\n",
    "        video_prediction.append(preds)\n",
    "        \n",
    "        labels = np.argsort(preds)[-1:-6:-1]\n",
    "        video_labels.append(labels)\n",
    "        \n",
    "        video_frames.append(video_path.strip())\n",
    "        \n",
    "    # Saving last frame of last video\n",
    "    video_targets = np.array(video_targets)\n",
    "    video_labels = np.array(video_labels)\n",
    "    video_prediction = np.array(video_prediction)\n",
    "    \n",
    "    num_frames = video_prediction.shape[0]\n",
    "    if num_frames < 10:\n",
    "        repeat_ids = np.round(np.linspace(0, num_frames - 1, 10)).astype(int)\n",
    "        video_targets = video_targets[repeat_ids]\n",
    "        video_labels = video_labels[repeat_ids]\n",
    "        video_prediction = video_prediction[repeat_ids]\n",
    "\n",
    "    clips_targets.append(video_targets)\n",
    "    clips_labels.append(video_labels)\n",
    "    clips_prediction.append(video_prediction)\n",
    "    clips_frames.append(video_frames)\n",
    "    \n",
    "                \n",
    "    return clips_targets, clips_labels, clips_prediction, clips_frames\n",
    "\n",
    "def select_n_clips(video_classes, n=10):\n",
    "    num_frames = len(video_classes)\n",
    "    ids = np.linspace(0, num_frames-1, n, dtype=int)\n",
    "    \n",
    "    return video_classes[ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dividing per clip\n",
    "clip_targets, clip_labels, clip_pred, clip_frames = divide_per_clip(split_text)\n",
    "\n",
    "\n",
    "# Getting all targets and labels\n",
    "all_targets = np.hstack(clip_targets)\n",
    "all_labels = np.vstack(clip_labels)\n",
    "\n",
    "\n",
    "# Getting result of 10 clips\n",
    "clip_pred_10 = [select_n_clips(np.array(clip_data), n=10) for clip_data in clip_pred]\n",
    "\n",
    "clip_pred_10_mean = np.array([t_c.mean(axis=0) for t_c in clip_pred_10])\n",
    "clip_gt_10 = np.array([clip_data[0] for clip_data in clip_targets])\n",
    "\n",
    "\n",
    "# Dividing all frames in percentages\n",
    "p_clip_targets = np.array([np.array_split(ct, 10) for ct in clip_targets])\n",
    "p_clip_labels = np.array([np.array_split(cl, 10) for cl in clip_labels])\n",
    "p_clip_pred = np.array([np.array_split(cp, 10) for cp in clip_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_videos = p_clip_targets.shape[0]\n",
    "num_percent = p_clip_targets.shape[1]\n",
    "num_topk = 5\n",
    "\n",
    "percentage_targets = np.zeros((num_videos, num_percent))\n",
    "percentage_pred = np.zeros((num_videos, num_percent, num_topk))\n",
    "\n",
    "for clip_id, (p_targets, p_preds) in enumerate(zip(p_clip_targets, p_clip_pred)):\n",
    "    for p_id in range(10):\n",
    "        pt = np.hstack(p_targets[:p_id+1])\n",
    "        pp = np.vstack(p_preds[:p_id+1])\n",
    "        assert len(set(pt)) == 1  # Checking if all targets match\n",
    "        percentage_targets[clip_id, p_id] = pt[0]\n",
    "        preds = torch.tensor(pp)\n",
    "        mean_pp = preds.mean(0)\n",
    "        _, topk_labels = torch.topk(mean_pp, 5)\n",
    "        percentage_pred[clip_id, p_id] = topk_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_predictions(video_pred, video_labels):\n",
    "    # TOP1\n",
    "    top1_pred = [p[0] for p in video_pred]\n",
    "    # TOP 5\n",
    "    top5_pred = []\n",
    "    for l, p in zip(video_labels, video_pred):\n",
    "        if l in p:\n",
    "            top5_pred.append(l)\n",
    "        else:\n",
    "            top5_pred.append(p[0])\n",
    "    return top1_pred, top5_pred\n",
    "\n",
    "\n",
    "def per_class_accuracy(predictions, labels):\n",
    "    cf = confusion_matrix(labels, predictions).astype(float)\n",
    "\n",
    "    cls_cnt = cf.sum(axis=1)\n",
    "    cls_hit = np.diag(cf)\n",
    "    return np.nanmean(cls_hit / cls_cnt), cls_hit.sum()/cls_cnt.sum()\n",
    "\n",
    "\n",
    "def get_per_frame_percent_results(p_targets, p_preds):\n",
    "    per_frame_percentage_results = []\n",
    "    for p_id in range(10):\n",
    "        p_t = p_targets[:, p_id]\n",
    "        p_p = p_preds[:, p_id]\n",
    "        top1_pred, top5_pred = get_top_predictions(p_p, p_t)\n",
    "\n",
    "        pcls_acc1, cls_acc1 = per_class_accuracy(top1_pred, p_t)\n",
    "        pcls_acc5, cls_acc5 = per_class_accuracy(top5_pred, p_t)\n",
    "        per_frame_percentage_results.append([cls_acc1, cls_acc5])\n",
    "        print('{}% - T1: {:.1%} (per-class: {:.1%}) | T5: {:.1%} (per-class: {:.1%})'.format(\n",
    "            (p_id+1)*10, cls_acc1, pcls_acc1, cls_acc5, pcls_acc5))\n",
    "    return np.array(per_frame_percentage_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: 65.13% | T5: 85.06%\n",
      "T1: 64.57% | T5: 84.66% (per class)\n"
     ]
    }
   ],
   "source": [
    "# All frames results\n",
    "\n",
    "top1_pred_all, top5_pred_all = get_top_predictions(all_labels, all_targets)\n",
    "\n",
    "pcls_acc1_all, cls_acc1_all = per_class_accuracy(top1_pred_all, all_targets)\n",
    "pcls_acc5_all, cls_acc5_all = per_class_accuracy(top5_pred_all, all_targets)\n",
    "\n",
    "print('T1: {:.2%} | T5: {:.2%}'.format(cls_acc1_all, cls_acc5_all))\n",
    "print('T1: {:.2%} | T5: {:.2%} (per class)'.format(pcls_acc1_all, pcls_acc5_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: 71.74% | T5: 90.06%\n",
      "T1: 71.67% | T5: 90.02% (per class)\n"
     ]
    }
   ],
   "source": [
    "# 10 clips results\n",
    "\n",
    "clip_top5_10 = []\n",
    "for mean_10 in clip_pred_10_mean:\n",
    "    _, topk_labels = torch.topk(torch.tensor(mean_10), 5)\n",
    "    clip_top5_10.append(topk_labels.numpy())\n",
    "    \n",
    "clip_top5_10 = np.array(clip_top5_10)\n",
    "\n",
    "top1_pred, top5_pred = get_top_predictions(clip_top5_10, clip_gt_10)\n",
    "\n",
    "pcls_acc1_10, cls_acc1_10 = per_class_accuracy(top1_pred, clip_gt_10)\n",
    "pcls_acc5_10, cls_acc5_10 = per_class_accuracy(top5_pred, clip_gt_10)\n",
    "\n",
    "print('T1: {:.2%} | T5: {:.2%}'.format(cls_acc1_10, cls_acc5_10))\n",
    "print('T1: {:.2%} | T5: {:.2%} (per class)'.format(pcls_acc1_10, pcls_acc5_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% - T1: 64.3% (per-class: 64.2%) | T5: 84.7% (per-class: 84.7%)\n",
      "20% - T1: 65.8% (per-class: 65.7%) | T5: 86.0% (per-class: 85.9%)\n",
      "30% - T1: 67.3% (per-class: 67.2%) | T5: 87.3% (per-class: 87.2%)\n",
      "40% - T1: 68.8% (per-class: 68.8%) | T5: 88.2% (per-class: 88.1%)\n",
      "50% - T1: 69.7% (per-class: 69.6%) | T5: 89.0% (per-class: 88.9%)\n",
      "60% - T1: 70.3% (per-class: 70.2%) | T5: 89.4% (per-class: 89.4%)\n",
      "70% - T1: 70.9% (per-class: 70.8%) | T5: 89.8% (per-class: 89.8%)\n",
      "80% - T1: 71.4% (per-class: 71.3%) | T5: 90.0% (per-class: 89.9%)\n",
      "90% - T1: 71.6% (per-class: 71.6%) | T5: 90.1% (per-class: 90.1%)\n",
      "100% - T1: 71.9% (per-class: 71.9%) | T5: 90.2% (per-class: 90.1%)\n"
     ]
    }
   ],
   "source": [
    "# All frames mean percentage results\n",
    "\n",
    "per_frame_percent_res = get_per_frame_percent_results(percentage_targets, percentage_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.concatenate((np.array([[cls_acc1_all, cls_acc5_all],[cls_acc1_10, cls_acc5_10]]), per_frame_percent_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = files_dir + '_results'\n",
    "np.save(output_file, results, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline8_centerCrop = np.load(output_file+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_baseline32_centerCrop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-19d5463c01d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_baseline32_centerCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_baseline32_centerCrop' is not defined"
     ]
    }
   ],
   "source": [
    "results_baseline32_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_nl32_centerCrop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3de60daf73af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_nl32_centerCrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_nl32_centerCrop' is not defined"
     ]
    }
   ],
   "source": [
    "results_nl32_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65134888, 0.85057376],\n",
       "       [0.71735596, 0.90061986],\n",
       "       [0.64277004, 0.8471192 ],\n",
       "       [0.65750432, 0.85951631],\n",
       "       [0.67254344, 0.87262473],\n",
       "       [0.6884971 , 0.88166853],\n",
       "       [0.69657555, 0.88969617],\n",
       "       [0.70297734, 0.8944213 ],\n",
       "       [0.70912509, 0.89848593],\n",
       "       [0.7137486 , 0.89980693],\n",
       "       [0.71649223, 0.90117874],\n",
       "       [0.71923585, 0.90173763]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_baseline8_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67416182, 0.8663481 ],\n",
       "       [0.73203943, 0.90747891],\n",
       "       [0.66421095, 0.85931308],\n",
       "       [0.67686211, 0.87257393],\n",
       "       [0.6923585 , 0.88354842],\n",
       "       [0.70414592, 0.89304949],\n",
       "       [0.71166548, 0.89807946],\n",
       "       [0.71837212, 0.9015344 ],\n",
       "       [0.72482471, 0.90458287],\n",
       "       [0.72919419, 0.90717407],\n",
       "       [0.73153135, 0.90829184],\n",
       "       [0.73341124, 0.90940961]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_baseline8_fullyConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66879506, 0.86181267],\n",
       "       [0.73468143, 0.90956204],\n",
       "       [0.66156895, 0.85850015],\n",
       "       [0.67737019, 0.871761  ],\n",
       "       [0.68936084, 0.88425973],\n",
       "       [0.70252007, 0.89284626],\n",
       "       [0.71283406, 0.89873997],\n",
       "       [0.71923585, 0.90356671],\n",
       "       [0.72431663, 0.9080378 ],\n",
       "       [0.72975307, 0.9093588 ],\n",
       "       [0.73290316, 0.91067981],\n",
       "       [0.73534194, 0.91159435]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nl8_centerCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69105737, 0.87622711],\n",
       "       [0.74524947, 0.91504928],\n",
       "       [0.67955492, 0.86835687],\n",
       "       [0.69246012, 0.88171934],\n",
       "       [0.70368865, 0.89330353],\n",
       "       [0.71659384, 0.90112793],\n",
       "       [0.7234529 , 0.90585306],\n",
       "       [0.730566  , 0.90991769],\n",
       "       [0.7357484 , 0.91245808],\n",
       "       [0.74011787, 0.91535413],\n",
       "       [0.74331877, 0.91631948],\n",
       "       [0.74438573, 0.91723402]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nl8_fullyConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
