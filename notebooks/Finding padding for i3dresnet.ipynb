{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import torchvision\n",
    "from torchvision.transforms import *\n",
    "\n",
    "import jpeg4py as jpeg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, time_kernel=1, space_stride=1,\n",
    "                 downsample=None, addnon=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes,\n",
    "                               planes,\n",
    "                               kernel_size=(time_kernel, 1, 1),\n",
    "                               padding=(int((time_kernel-1)/2), 0, 0),\n",
    "                               bias=False)  # timepadding: make sure time-dim not reduce\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = nn.Conv3d(planes,\n",
    "                               planes,\n",
    "                               kernel_size=(1, 3, 3),\n",
    "                               stride=(1, space_stride, space_stride),\n",
    "                               padding=(0, 1, 1),\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = nn.Conv3d(planes,\n",
    "                               planes * 4,\n",
    "                               kernel_size=(1, 1, 1),\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.addnon = addnon\n",
    "        if self.addnon:\n",
    "            self.nonlocal_block = NonLocalBlock3D(in_channels=planes * 4, mode='embedded_gaussian')\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        if self.addnon:\n",
    "            out = self.nonlocal_block(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class I3DResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, frame_num=32, num_classes=400):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        self.inplanes = 64\n",
    "        super(I3DResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64,\n",
    "                               kernel_size=(5, 7, 7),\n",
    "                               stride=(2, 2, 2),\n",
    "                               padding=(0, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        self.layer1 = self._make_layer_inflat(block, 64, layers[0], first_block=True)\n",
    "        self.temporalpool = nn.MaxPool3d(kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0))\n",
    "        self.layer2 = self._make_layer_inflat(block, 128, layers[1], space_stride=2)\n",
    "        self.layer3 = self._make_layer_inflat(block, 256, layers[2], space_stride=2)\n",
    "        self.layer4 = self._make_layer_inflat(block, 512, layers[3], space_stride=2)\n",
    "        self.avgpool = nn.AvgPool3d((int(frame_num/8), 7, 7))\n",
    "        self.avgdrop = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer_inflat(self, block, planes, blocks, space_stride=1, first_block=False):\n",
    "        downsample = None\n",
    "        if space_stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=(1, 1, 1), stride=(1, space_stride, space_stride),\n",
    "                          bias=False),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        if blocks % 2 == 0 or first_block:\n",
    "            time_kernel = 3\n",
    "        else:\n",
    "            time_kernel = 1\n",
    "\n",
    "        # Add first block\n",
    "        layers.append(block(self.inplanes, planes, time_kernel, space_stride, downsample,\n",
    "                            addnon=False))\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        if first_block:\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "        elif blocks % 2 == 0:\n",
    "            time_kernel = 1\n",
    "            add_nonlocal = True\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel, addnon=add_nonlocal))\n",
    "                time_kernel = (time_kernel + 2) % 4\n",
    "                add_nonlocal = not add_nonlocal\n",
    "        else:\n",
    "            time_kernel = 3\n",
    "            for i in range(1, blocks):\n",
    "                layers.append(block(self.inplanes, planes, time_kernel))\n",
    "                time_kernel = (time_kernel + 2) % 4\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.temporalpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.avgdrop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class _NonLocalBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded_gaussian',\n",
    "                 sub_sample=True, bn_layer=True):\n",
    "        super(_NonLocalBlockND, self).__init__()\n",
    "\n",
    "        assert mode in ['embedded_gaussian', 'gaussian', 'dot_product', 'concatenation']\n",
    "\n",
    "        self.mode = mode\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        self.g = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        nn.init.kaiming_normal_(self.g.weight)\n",
    "        nn.init.constant_(self.g.bias, 0)\n",
    "\n",
    "        if bn_layer:\n",
    "            self.W = nn.Sequential(\n",
    "                nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                          kernel_size=1, stride=1, padding=0),\n",
    "                nn.BatchNorm3d(self.in_channels)\n",
    "            )\n",
    "            nn.init.kaiming_normal_(self.W[0].weight)\n",
    "            nn.init.constant_(self.W[0].bias, 0)\n",
    "            nn.init.constant_(self.W[1].weight, 0)\n",
    "            nn.init.constant_(self.W[1].bias, 0)\n",
    "\n",
    "        else:\n",
    "            self.W = nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "            nn.init.kaiming_normal(self.W.weight)\n",
    "            nn.init.constant(self.W.bias, 0)\n",
    "\n",
    "        self.theta = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if self.mode == \"embedded_gaussian\":\n",
    "            self.operation_function = self._embedded_gaussian\n",
    "        else:\n",
    "            raise NotImplementedError('Non-local mode: {} not implemented!'.format(self.mode))\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, nn.MaxPool3d(kernel_size=(1, 2, 2)))\n",
    "            self.phi = nn.Sequential(self.phi, nn.MaxPool3d(kernel_size=(1, 2, 2)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        output = self.operation_function(x)\n",
    "        return output\n",
    "\n",
    "    def _embedded_gaussian(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # g=>(b, c, t, h, w)->(b, 0.5c, t, h, w)->(b, thw, 0.5c)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        # theta=>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, thw, 0.5c)\n",
    "        # phi  =>(b, c, t, h, w)[->(b, 0.5c, t, h, w)]->(b, 0.5c, thw)\n",
    "        # f=>(b, thw, 0.5c)dot(b, 0.5c, twh) = (b, thw, thw)\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        # (b, thw, thw)dot(b, thw, 0.5c) = (b, thw, 0.5c)->(b, 0.5c, t, h, w)->(b, c, t, h, w)\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class NonLocalBlock3D(_NonLocalBlockND):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded_gaussian',\n",
    "                 sub_sample=True, bn_layer=True):\n",
    "        super(NonLocalBlock3D, self).__init__(in_channels,\n",
    "                                              inter_channels=inter_channels,\n",
    "                                              mode=mode,\n",
    "                                              sub_sample=sub_sample,\n",
    "                                              bn_layer=bn_layer)\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = I3DResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def copy_weigths_i3dResNet(weigths_file_path, new_model, save_model=False, new_model_name=None):\n",
    "    with open(weigths_file_path, 'rb') as model_file:\n",
    "        pretrained_data = pickle.load(model_file, encoding='latin1')\n",
    "\n",
    "    pretrained_data1 = pretrained_data['blobs']\n",
    "    # Removing training parameters\n",
    "    pretrained_data2 = {k: v for k, v in pretrained_data1.items() if\n",
    "                        ('momentum' not in k) and ('bn_rm' not in k) and ('bn_riv' not in k)\n",
    "                        and ('lr' not in k) and ('model_iter' not in k)}\n",
    "\n",
    "    # Absorb std to conv1\n",
    "    data_std = [0.225, 0.225, 0.225]\n",
    "    w = pretrained_data2['conv1_w']\n",
    "    for i in range(3):\n",
    "        w[:, i, :, :, :] /= data_std[i]\n",
    "    assert(np.array_equal(pretrained_data2['conv1_w'], w))\n",
    "\n",
    "    pretrained_data_list = sorted(pretrained_data2.items())\n",
    "\n",
    "    # Renaming layers\n",
    "    pretrained_data3 = {}\n",
    "    for k, v in pretrained_data_list:\n",
    "        a = k[:]\n",
    "        # Correcting the end\n",
    "        if a[-2:] == '_b':\n",
    "            a = a[:-2]+'.bias'\n",
    "        elif a[-2:] == '_s' or a[-2:] == '_w':\n",
    "            a = a[:-2]+'.weight'\n",
    "\n",
    "        # Correcting the begin\n",
    "        a = a.replace('res_conv1_bn', 'bn1')\n",
    "        a = a.replace('pred', 'fc')\n",
    "        r = re.compile('res._*')\n",
    "        if r.match(a) is not None:\n",
    "            layer = int(a[3])-1\n",
    "            a = 'layer'+str(layer)+'.'+a[5:]\n",
    "\n",
    "        # Correcting the middle\n",
    "        a = a.replace('_branch1_bn', '.downsample.1')\n",
    "        a = a.replace('_branch1', '.downsample.0')\n",
    "\n",
    "        for i, l in enumerate(['a', 'b', 'c']):\n",
    "            a = a.replace('_branch2{}_bn'.format(l), '.bn{}'.format(i+1))\n",
    "            a = a.replace('_branch2{}'.format(l), '.conv{}'.format(i+1))\n",
    "\n",
    "        # Correcting nonlocal\n",
    "        if 'nonlocal' in a:\n",
    "            layer = int(a[13])-1\n",
    "            sub_layer = a[15]\n",
    "            a = 'layer{}.{}.nonlocal_block.'.format(layer, sub_layer) + a[17:]\n",
    "            a = a.replace('out', 'W.0')\n",
    "            a = a.replace('bn', 'W.1')\n",
    "            a = a.replace('phi', 'phi.0')\n",
    "            a = a.replace('.g.', '.g.0.')\n",
    "\n",
    "        pretrained_data3[a] = {'old_name': k, 'data': v}\n",
    "\n",
    "    # Checking name, shape and number of layers\n",
    "    param_i3d_keys = new_model.state_dict().keys()\n",
    "    count = 0\n",
    "    for k, v in pretrained_data3.items():\n",
    "        assert(k in param_i3d_keys)\n",
    "        count += 1\n",
    "        assert(new_model.state_dict()[k].shape == v['data'].shape)\n",
    "\n",
    "    assert count == len(list(new_model.named_parameters()))\n",
    "\n",
    "    # Copying weigths\n",
    "    for k, v in new_model.named_parameters():\n",
    "        new_data = pretrained_data3[k]['data']\n",
    "        v.data = nn.Parameter(torch.Tensor(new_data))\n",
    "\n",
    "    if save_model:\n",
    "        # Saving new model\n",
    "        torch.save(new_model, '{}.pt'.format(new_model_name))\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fa2c05cbbe87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pre_trained_file = (\"/media/v-pakova/New Volume/OnlineActionRecognition/models/pre-trained/\"\n\u001b[1;32m      2\u001b[0m                     \"non-local/i3d_nonlocal_32x2_IN_pretrain_400k.pkl\")\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mblank_resnet_i3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mi3d_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_weigths_i3dResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_trained_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblank_resnet_i3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-09e67eac81c2>\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mpretrained\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0mon\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI3DResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-09e67eac81c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, layers, frame_num, num_classes)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                                bias=False)\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m         super(Conv3d, self).__init__(\n\u001b[1;32m    442\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             False, _triple(0), groups, bias)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             self.weight = Parameter(torch.Tensor(\n\u001b[0;32m---> 38\u001b[0;31m                 out_channels, in_channels // groups, *kernel_size))\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "pre_trained_file = (\"/media/v-pakova/New Volume/OnlineActionRecognition/models/pre-trained/\"\n",
    "                    \"non-local/i3d_nonlocal_32x2_IN_pretrain_400k.pkl\")\n",
    "blank_resnet_i3d = resnet50()\n",
    "i3d_model = copy_weigths_i3dResNet(pre_trained_file, blank_resnet_i3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I3DResNet(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(0, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (temporalpool): MaxPool3d(kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), dilation=1, ceil_mode=False)\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (nonlocal_block): NonLocalBlock3D(\n",
       "        (g): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (W): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (phi): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (nonlocal_block): NonLocalBlock3D(\n",
       "        (g): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (W): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (theta): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (phi): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (nonlocal_block): NonLocalBlock3D(\n",
       "        (g): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (W): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (phi): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (nonlocal_block): NonLocalBlock3D(\n",
       "        (g): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (W): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (phi): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (nonlocal_block): NonLocalBlock3D(\n",
       "        (g): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (W): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (theta): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (phi): Sequential(\n",
       "          (0): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
       "        (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(4, 7, 7), stride=(4, 7, 7), padding=0)\n",
       "  (avgdrop): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=2048, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i3d_model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecord(object):\n",
    "    def __init__(self, row):\n",
    "        self._data = row\n",
    "\n",
    "    @property\n",
    "    def label(self):\n",
    "        return int(self._data[0])\n",
    "\n",
    "    @property\n",
    "    def path(self):\n",
    "        return self._data[1]\n",
    "\n",
    "    @property\n",
    "    def num_frames(self):\n",
    "        return int(self._data[2])\n",
    "\n",
    "\n",
    "class I3DDataSet(data.Dataset):\n",
    "    def __init__(self, root_path, list_file, sample_frames=32,\n",
    "                 image_tmpl='frame_{:06d}.jpg', transform=None,\n",
    "                 force_grayscale=False, train_mode=True, test_clips=10, chunk_set=None):\n",
    "        self.root_path = root_path\n",
    "        self.list_file = list_file\n",
    "        self.sample_frames = sample_frames\n",
    "        self.image_tmpl = image_tmpl\n",
    "        self.train_mode = train_mode\n",
    "        if not self.train_mode:\n",
    "            self.num_clips = test_clips\n",
    "\n",
    "        if train_mode is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = t.GroupToTensorStack()\n",
    "\n",
    "        self._parse_list(chunk_set)\n",
    "\n",
    "    def _load_image(self, video_dir, idx):\n",
    "        img_path = os.path.join(self.root_path, video_dir, self.image_tmpl.format(idx))\n",
    "        try:\n",
    "            # Loading images with PIL is much slower!!\n",
    "            return [Image.fromarray(jpeg.JPEG(img_path).decode())]\n",
    "        except IOError:\n",
    "            print(\"Couldn't load image:{}\".format(img_path))\n",
    "            return None\n",
    "\n",
    "    def _parse_list(self, chunk_set):\n",
    "        self.video_list = [VideoRecord(x.strip().split(' ')) for x in open(self.list_file)]\n",
    "        if chunk_set is not None:\n",
    "            self.video_list = self.video_list[chunk_set[0]:chunk_set[1]]\n",
    "\n",
    "    def _sample_indices(self, record):\n",
    "        \"\"\"\n",
    "        :param record: VideoRecord\n",
    "        :return: list\n",
    "        \"\"\"\n",
    "        expanded_sample_length = self.sample_frames * 4  # in order to drop every other frame\n",
    "        if record.num_frames >= expanded_sample_length:\n",
    "            start_pos = randint(record.num_frames - expanded_sample_length + 1)\n",
    "            offsets = range(start_pos, start_pos + expanded_sample_length, 4)\n",
    "        elif record.num_frames > self.sample_frames*2:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames*2 + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames*2, 2)\n",
    "        elif record.num_frames > self.sample_frames:\n",
    "            start_pos = randint(record.num_frames - self.sample_frames + 1)\n",
    "            offsets = range(start_pos, start_pos + self.sample_frames, 1)\n",
    "        else:\n",
    "            offsets = np.sort(randint(record.num_frames, size=self.sample_frames))\n",
    "\n",
    "        offsets = [int(v) for v in offsets]\n",
    "        return offsets\n",
    "\n",
    "    def _get_test_indices(self, record):\n",
    "        tick = (record.num_frames - self.sample_frames*2 + 1) / float(self.num_clips)\n",
    "#         sample_start_pos = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_clips)])\n",
    "        sample_start_pos = np.array([int(tick * x) for x in range(self.num_clips)])\n",
    "        offsets = []\n",
    "        for p in sample_start_pos:\n",
    "            offsets.extend(range(p, p+self.sample_frames*2, 2))\n",
    "\n",
    "        checked_offsets = []\n",
    "        for f in offsets:\n",
    "            new_f = int(f)\n",
    "            if new_f < 0:\n",
    "                new_f = 0\n",
    "            elif new_f >= record.num_frames:\n",
    "                new_f = record.num_frames - 1\n",
    "            checked_offsets.append(new_f)\n",
    "\n",
    "        return checked_offsets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        record = self.video_list[index]\n",
    "\n",
    "        if self.train_mode:\n",
    "            segment_indices = self._sample_indices(record)\n",
    "            process_data, label = self.get(record, segment_indices)\n",
    "            while process_data is None:\n",
    "                index = randint(0, len(self.video_list) - 1)\n",
    "                process_data, label = self.__getitem__(index)\n",
    "        else:\n",
    "            segment_indices = self._get_test_indices(record)\n",
    "            process_data, label = self.get(record, segment_indices)\n",
    "            if process_data is None:\n",
    "                raise ValueError('sample indices:', record.path, segment_indices)\n",
    "\n",
    "        return process_data, label\n",
    "\n",
    "    def get(self, record, indices):\n",
    "        uniq_imgs = {}\n",
    "        uniq_id = np.unique(indices)\n",
    "        for ind in uniq_id:\n",
    "            seg_img = self._load_image(record.path, ind)\n",
    "            if seg_img is None:\n",
    "                return None, None\n",
    "            uniq_imgs[ind] = seg_img\n",
    "\n",
    "        images = [uniq_imgs[i][0] for i in indices]\n",
    "        images = self.transform(images)\n",
    "        return images, record.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "\n",
    "    \n",
    "    \n",
    "class GroupToTensorStack(object):\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        return torch.stack([torchvision.transforms.ToTensor()(img) for img in img_group], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = '/media/v-pakova/New Volume/Datasets/Kinetics/400/val_list_short.txt'\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        I3DDataSet(\"/media/v-pakova/New Volume/Datasets/Kinetics/400/val_frames_256\", \n",
    "                   test_list, \n",
    "                   image_tmpl=\"frame_{:06d}.jpg\",\n",
    "                   train_mode=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                       GroupToTensorStack(),\n",
    "                    ])),\n",
    "        batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "data_gen = enumerate(data_loader)\n",
    "total_num = len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b7c9a47a55ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (data, label) in data_gen:\n",
    "    data = data.to(device)\n",
    "    data = data.squeeze(0)\n",
    "    data = data.view(num_channel, -1, num_depth, data.size(2), data.size(3)).contiguous()\n",
    "    data = data.permute(1, 0, 2, 3, 4).contiguous()\n",
    "    # print(data.shape)\n",
    "\n",
    "    i3d_model(data).mean(0).cpu()\n",
    "    \n",
    "    if i >3:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
