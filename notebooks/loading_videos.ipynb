{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.CAP_PROP_FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecord(object):\n",
    "    def __init__(self, video_path, label):\n",
    "        self.path = video_path\n",
    "        self.video = cv2.VideoCapture(self.path)\n",
    "        # Getting some properties after the first frame\n",
    "        self.cv2_num_frames = self.video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        self.num_frames = self._get_num_frames()\n",
    "        self.label = label\n",
    "\n",
    "    def _get_num_frames(self):\n",
    "        count = 0\n",
    "        success, frame = self.video.read()\n",
    "        if not success:\n",
    "            print('Failed to load video {}'.format(self.path))\n",
    "            \n",
    "\n",
    "        while(success):\n",
    "            success, frame = self.video.read()\n",
    "            count += 1\n",
    "        self.video.set(2, 0)\n",
    "\n",
    "        return count\n",
    "\n",
    "    def get_frames(self, indices):\n",
    "        \"\"\"\n",
    "        Argument:\n",
    "            indices : Sorted list of frames indices\n",
    "        Returns:\n",
    "            images : Dictionary in format {frame_id: PIL Image}\n",
    "        \"\"\"\n",
    "        images = dict()\n",
    "        self.video.set(cv2.CAP_PROP_POS_FRAMES, min(indices))\n",
    "        for count in range(min(indices), max(indices)+1):\n",
    "            success, frame = self.video.read()\n",
    "            if success is False:\n",
    "                print('\\nCould not load frame {} from video {}\\n'.format(count, self.path))\n",
    "                return None\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            if count in indices:\n",
    "                images[count] = Image.fromarray(frame)\n",
    "\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(list_file):\n",
    "        video_list = []\n",
    "        with open(list_file) as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                vid = row['id']\n",
    "                actions = row['actions']\n",
    "                length = row['length']\n",
    "                if actions == '':\n",
    "                    actions = []\n",
    "                else:\n",
    "                    actions = [a.split(' ') for a in actions.split(';')]\n",
    "                    actions = [{'class': x, 'start': float(\n",
    "                        y), 'end': float(z)} for x, y, z in actions]\n",
    "                video_list.append([actions, vid, length])\n",
    "                \n",
    "        return video_list\n",
    "\n",
    "train_file = '/media/v-pakova/Datasets/Charades/Annotations/Charades_v1_train.csv'\n",
    "test_file = '/media/v-pakova/Datasets/Charades/Annotations/Charades_v1_test.csv'\n",
    "root_path = '/media/v-pakova/Datasets/Charades/Charades_v1_480'\n",
    "num_classes = 157\n",
    "FPS = 24\n",
    "\n",
    "video_list = parse_list(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4685681c8b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     print('FPS: {:.02f}, {:.02f}, {:.02f}'.format(record.cv2_fps, fps3, fps4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_num_frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-3cbc21aff60a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, video_path, label)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Getting some properties after the first frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_num_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_num_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-3cbc21aff60a>\u001b[0m in \u001b[0;36m_get_num_frames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, (label, vid, length) in enumerate(video_list):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "\n",
    "    record = VideoRecord(os.path.join(root_path, vid+'.mp4'), label)\n",
    "#     print('FPS: {:.02f}, {:.02f}, {:.02f}'.format(record.cv2_fps, fps3, fps4))\n",
    "    assert float(record.num_frames) == record.cv2_num_frames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "360.0, 362.0\n",
      "360.0, 360.0\n",
      "360.0, 360.0\n",
      "360.0, 360.0\n",
      "360.0, 360.0\n",
      "288.0, 290.0\n",
      "719.0, 720.0\n",
      "360.0, 360.0\n",
      "360.0, 360.0\n",
      "244.0, 248.0\n"
     ]
    }
   ],
   "source": [
    "kinetics_file =  '/media/v-pakova/Datasets/Kinetics/400/Annotation/val_clips_256_list.txt'\n",
    "kinetics_root_path =  '/media/v-pakova/Datasets/Kinetics/400/val_clips_256'\n",
    "\n",
    "kinetics_list = [x.strip().split(' ') for x in open(kinetics_file)]\n",
    "\n",
    "for i, (label, vid) in enumerate(kinetics_list[:10]):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "\n",
    "    record = VideoRecord(os.path.join(kinetics_root_path, vid), label)\n",
    "#     print('FPS: {:.02f}, {:.02f}, {:.02f}'.format(record.cv2_fps, fps3, fps4))\n",
    "#     assert float(record.num_frames) == record.cv2_num_frames, '{}, {}'.format(float(record.num_frames), record.cv2_num_frames)\n",
    "    print('{}, {}'.format(float(record.num_frames), record.cv2_num_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.CAP_PROP_POS_AVI_RATIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
